# -*- coding: utf-8 -*-
"""Final Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CeChn1CVlHp7JLOTA4OqS3-PQj5wF2R0
"""

!pip install accelerate
!pip install transformers optimum
!pip install auto-gptq
!pip install transformers
!pip install sacremoses

import time
import torch
import torch.nn as nn
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline

class GenerativeModel_Mistral:
  def __init__(self):
    self.path = "TheBloke/Mistral-7B-OpenOrca-GPTQ"
    self.generative_model = AutoModelForCausalLM.from_pretrained(self.path,
                                             device_map="auto")

    self.tokenizer = AutoTokenizer.from_pretrained(self.path)

  def generate(self, input_text, max_new_tokens=512):

    s = time.time_ns()
    inputs = self.tokenizer(input_text, max_length=1024, truncation=True, return_tensors='pt').to('cuda')

    with torch.no_grad():
      out = self.generative_model.generate(**inputs,
                                             max_new_tokens=max_new_tokens)
    out_str = self.tokenizer.decode(out[0], skip_special_tokens = True)

    e = time.time_ns()
    return{'elapsed_time': ((e-s)//1000000)/1000,'output': out_str}

class GenerativeModel_Llama:
  def __init__(self):
    self.path = "TheBloke/Llama-2-7b-Chat-GPTQ"
    self.generative_model = AutoModelForCausalLM.from_pretrained(self.path,
                                             device_map="auto")

    self.tokenizer = AutoTokenizer.from_pretrained(self.path)

  def generate(self, input_text, max_new_tokens=512):

    s = time.time_ns()
    inputs = self.tokenizer(input_text, max_length=1024, truncation=True, return_tensors='pt').to('cuda')

    with torch.no_grad():
      out = self.generative_model.generate(**inputs,
                                             max_new_tokens=max_new_tokens)
    out_str = self.tokenizer.decode(out[0], skip_special_tokens = True)

    e = time.time_ns()
    return{'elapsed_time': ((e-s)//1000000)/1000,'output': out_str}

from transformers import MarianMTModel, MarianTokenizer

class Translator:

  def __init__(self):

    access_token = "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"

    self.tr_en_model_name = "Helsinki-NLP/opus-mt-tc-big-tr-en"
    self.tr_en_tokenizer = MarianTokenizer.from_pretrained(self.tr_en_model_name, token=access_token)
    self.tr_en_model = MarianMTModel.from_pretrained(self.tr_en_model_name, token=access_token)
    self.tr_en_model.to('cuda')

    self.en_tr_model_name = "Helsinki-NLP/opus-mt-tc-big-en-tr"
    self.en_tr_tokenizer = MarianTokenizer.from_pretrained(self.en_tr_model_name,token=access_token)

    self.en_tr_model = MarianMTModel.from_pretrained(self.en_tr_model_name,token=access_token)
    self.en_tr_model.to('cuda')

  def tr_to_en(self,tr_str):
    s = time.time_ns()
    tokenized = self.tr_en_tokenizer(tr_str,return_tensors="pt",padding=True,truncation=True).to('cuda')
    out = self.tr_en_model.generate(**tokenized)
    translated = self.tr_en_tokenizer.decode(out[0],skip_special_tokens=True)

    e = time.time_ns()
    return{'input_translation_time': ((e-s)//1000000)/1000,'output': translated}

  def en_to_tr(self,en_str):
    s = time.time_ns()
    tokenized = self.en_tr_tokenizer(en_str,return_tensors="pt",padding=True,truncation=True).to('cuda')
    out = self.en_tr_model.generate(**tokenized)
    translated = self.en_tr_tokenizer.decode(out[0],skip_special_tokens=True)

    e = time.time_ns()
    return{'elapsed_time_translator': ((e-s)//1000000)/1000,'output': translated}

class Template_llama:
  template = \
  """
  <s>[INST] <<SYS>>
  Find out what the customers are satisfied and dissatisfied with based on the content of the text group.
  Just separate positive and negative things based on the text group.
  Each comment in the text group belongs to a different customer.
  Don't explain anything.

  You should write like that:
  Positive
  * <|positive_thing|>
  * <|positive_thing|>

  Negative
  * <|negative_thing|>
  * <|negative_thing|>

  <</SYS>>
  Tell me what is negative and what is positive in the text group.
  Comments: {}

  [/INST]
  Answer:
  """

class Template_mistral:
  template = \
  """
  <s><|im_start|>system
  Find out what the customers are satisfied and dissatisfied with based on the content of the text group.
  Just separate positive and negative things based on the text group.
  Each comment in the text group belongs to a different customer.
  Don't explain anything.

  Here is an example for answer format:
  "
  Positive
  * <|positive_thing|>
  * <|positive_thing|>

  Negative
  * <|negative_thing|>
  * <|negative_thing|>
  "

  <|im_start|>user
  Tell me what is negative and what is positive in the text group.
  Comments: {}<|im_end|>

  <|im_start|>assistant
  Answer: """

class LLMEngine:
  def __init__(self, model=None):
    self.k = 0
    self.model = model
    if not model:
      self.model = GenerativeModel_Mistral()
      self.k = 1
    self.translator = Translator()

  def positive_negative(self, text_list, lang='tr'):

    if lang == 'tr':
      text_list = [self.translator.tr_to_en(text)['output'] for text in text_list]
      ep_list = [self.translator.tr_to_en(text)['input_translation_time'] for text in text_list]
      ep_translator = sum(ep_list)
    lines = '\n* '+'\n* '.join(text_list)
    lines = lines[:400]
    if self.k == 1:
      template = Template_mistral.template.format(lines)
    else:
      template = Template_llama.template.format(lines)
    out = self.model.generate(template, max_new_tokens=300)
    elapsed_time = out['elapsed_time']
    raw_out = out['output']
    raw_out = raw_out[raw_out.find('[/INST]')+8:]
    raw_out = raw_out[raw_out.find('Answer: ')+8:]

    if lang == 'tr':
      out_str = self.translator.en_to_tr(raw_out)
    else:
      out_str = raw_out

    return{'elapsed_time_model': elapsed_time,
           'input_translation_time': ep_translator,
           'out_translation_time': out_str['elapsed_time_translator'],
           'total_translation_time' : out_str['elapsed_time_translator'] + ep_translator,
           'output' : out_str['output'],
           'raw_out' : raw_out}

llama = LLMEngine(model=GenerativeModel_Llama())

mistral = LLMEngine()

test_text = [["Bu ürünü aldığıma gerçekten memnunum! Kaliteli malzemelerden yapılmış, dayanıklı ve kullanımı çok kolay. Fiyat performans açısından da gayet başarılı.", "Ürünün beklediğim performansı vermedi maalesef. Kullanımı oldukça karmaşık ve bazı fonksiyonları tam olarak çalışmıyor. Biraz daha iyileştirme yapılması gerektiğini düşünüyorum.", "Harika bir ürün! Hem tasarımı hem de işlevselliğiyle beni etkiledi. Kullanımı çok kolay ve sağlam bir yapıya sahip. Kesinlikle tavsiye ederim.", "Ürünün kalitesi beklediğimden düşük çıktı. İlk kullanımdan sonra bazı sorunlar yaşamaya başladım ve garanti kapsamında değişim talep ettim. Daha dikkatli bir şekilde üretim yapılmalı.", "Bu ürünü almadan önce birçok alternatif araştırdım ve sonunda en iyisi olduğuna karar verdim. Gerçekten doğru bir seçim yapmışım, performansı ve dayanıklılığıyla beni şaşırttı.", "Ürünü ilk aldığımda gayet memnundum ancak kısa süre sonra bazı sorunlar yaşamaya başladım. Müşteri hizmetleriyle iletişime geçtim ancak sorunum hala çözülmedi. Hayal kırıklığına uğradım.", "Bu ürün gerçekten kaliteli bir tasarıma sahip. İşlevselliği mükemmel ve kullanımı oldukça kolay. Herkese rahatlıkla tavsiye edebilirim.", "Ürünün fiyatına göre performansı oldukça düşük. Beklediğim verimi alamadım ve birkaç haftalık kullanımdan sonra bazı fonksiyonları tamamen işlevsiz hale geldi. Dezavantajları göz önünde bulundurarak almanızı önermem.", "Bu ürünü kullanmaya başladıktan sonra hayatım çok daha kolaylaştı. İhtiyacım olan her şeyi tek bir yerde bulabiliyorum ve performansından oldukça memnunum. Kesinlikle alınması gereken bir ürün.", "Ürünü aldığımdan beri sürekli sorun yaşıyorum. Hem tasarımı hem de performansı beklediğimden çok daha kötü çıktı. Bu fiyata alınabilecek daha iyi alternatifler olduğunu düşünüyorum."]]

test_text

mistral.positive_negative(test_text[0])

llama.positive_negative(test_text[0])

comments = [["Harika bir ses kalitesi ve kablosuz özgürlük! Kesinlikle tavsiye ederim.", "Çok rahat, hafif ve pratik. Spor yaparken kullanmak için mükemmel bir seçim.", "Bağlantı bazen kesiliyor, özellikle yoğun yerlerde kullanırken sıkıntı yaşanabiliyor.", "Şarj süresi beklediğimden kısa, sık sık şarj etmek zorunda kalıyorum.", "Kolay bağlantı ve kullanım, mükemmel gürültü engelleme. Bu fiyata çok iyi bir ürün.", "Kulak içine yerleştirme konusunda biraz rahatsız edici, uzun süre kullanımda ağrı yapabiliyor."], ["Hızlı işlemci, etkileyici kamera ve şık tasarım. En iyi telefonlardan biri!", "Yüksek performans ve dayanıklılık, her türlü uygulama ve oyunu sorunsuz çalıştırıyor.", "Fiyatı biraz yüksek, daha uygun fiyatlı alternatifler tercih edilebilir.", "Mükemmel ekran kalitesi, uzun pil ömrü ve akıcı kullanıcı arayüzü. Kesinlikle öneririm.", "Bazı kullanıcılar arasında yazılım güncellemeleriyle ilgili sorunlar yaşanabiliyor.", "Parmak izi okuyucu bazen çalışmıyor, bu da güvenlik açısından endişe verici olabiliyor."], ["Takılıp kaldığı yerler olabiliyor, bazen manuel müdahale gerektirebiliyor.", "Ses seviyesi biraz yüksek, sessiz çalışan bir model tercih edilebilir.", "Evinizi temizlemek için harika bir yardımcı, akıllı navigasyon ve güçlü emiş gücü.", "Programlanabilir ve uzaktan kontrol edilebilir özellikleriyle hayatı kolaylaştırıyor.", "Köşe ve kenarları temizlemekte çok etkili, evcil hayvan sahipleri için ideal bir seçim.", "Pil ömrü beklediğimden kısa, büyük alanları temizlemek için birden fazla şarj gerekebiliyor."], ["Bazı kullanıcılar arasında Bluetooth bağlantı sorunları yaşanabiliyor, cihazlar arasında iletişim kopuklukları olabiliyor.", "Ekran boyutu biraz küçük, bazı kullanıcılar için bilgi okunması zor olabilir.", "Yüzeyi çabuk çiziliyor, ekranı koruyucu kullanmak gerekebiliyor.", "Sağlık takibi, spor aktiviteleri ve bildirimler için mükemmel bir yardımcı, şık tasarımıyla da dikkat çekiyor.", "Uzun pil ömrü, suya dayanıklılık ve geniş uygulama desteği. Herkesin sahip olması gereken bir aksesuar.", "Uygun fiyatlı olmasına rağmen kaliteli malzeme ve fonksiyonlara sahip, performansıyla şaşırtıyor."], ["Fiyatı biraz yüksek, bütçesi kısıtlı olanlar için alternatif arayışı gerekebilir.", "Yüksek performans, uzun pil ömrü ve şık tasarım. Hem iş hem de eğlence için mükemmel bir seçim.", "Fan sesi bazen rahatsız edici olabiliyor, sessiz çalışan bir model tercih edilebilir.", "Hızlı açılış ve tepki verme süresi, çoklu görevleri rahatça yönetmek için ideal.", "Isınma sorunu yaşayan kullanıcılar var, uzun süreli kullanımlarda cihazın sıcaklığı artabiliyor.", "Taşınabilirlik ve güçlü donanım kombinasyonuyla en iyi dizüstü bilgisayarlar arasında yer alıyor."], ["Mükemmel kahve demleme performansı, kolay temizlik ve şık tasarım. Sabahları benim için vazgeçilmez!", "Farklı kahve çeşitlerini kolayca hazırlama imkanı, kullanımı da oldukça pratik.", "Büyük su haznesi ve otomatik kapanma özelliği ile güvenli ve kullanışlı bir ürün.", "Bazı modellerde su sızıntısı problemi yaşanabiliyor, dikkatli olmak gerekiyor.", "Filtre değişim maliyetleri zamanla artabiliyor, bu da bakım masraflarını artırıyor.", "Sıcaklık kontrolü biraz zor, bazen istenilen kahve sıcaklığına ulaşmak mümkün olmayabiliyor."], ["Şarj süresi biraz uzun, beklemek gerekebiliyor. Daha hızlı şarj eden modeller tercih edilebilir.", "Bazı modellerde bağlantı sorunları yaşanabiliyor, cihazlar arasında iletişim kopuklukları olabiliyor.", "Hızlı şarj özelliği ve yüksek kapasitesi ile hayat kurtarıcı bir ürün. Her zaman yanımda taşıyorum!", "Kompakt tasarımı ve hafif yapısıyla taşınması kolay, seyahatlerde büyük bir avantaj sağlıyor.", "Birden fazla cihazı aynı anda şarj edebilme özelliği, çoklu kullanıcılar için ideal.", "Dayanıklılık konusunda sorunlar yaşanabiliyor, düşmelere karşı daha sağlam bir yapı tercih edilebilir."], ["Mükemmel ses kalitesi, şık tasarım ve kablosuz bağlantı özelliği ile her yerde kullanılabilir.", "Pil ömrü biraz kısa, uzun süreli kullanımlarda sık sık şarj etmek gerekiyor.", "Bazı kullanıcılar arasında bağlantı kopmaları yaşanabiliyor, stabil bir bağlantı için daha güçlü sinyal gerekiyor.", "Bass performansı biraz zayıf, daha güçlü bir bas isteyenler için yeterli olmayabilir.", "Taşınabilirlik açısından ideal, pikniklerde, plajda veya ev partilerinde vazgeçilmezimiz haline geldi.", "Su geçirmez özelliği sayesinde dış mekanlarda kullanımı sorunsuz, dayanıklı bir yapıya sahip."], ["Bazı modellerde ses seviyesi biraz yüksek, çalışırken rahatsız edici olabiliyor.", "Hızlı pişirme özelliği, geniş iç hacim ve kullanım kolaylığı ile mutfağın vazgeçilmezi oldu.", "Farklı pişirme programları ve hassas ayarlar sayesinde her yemeği mükemmel şekilde pişirebiliyorum.", "Kolay temizlenebilir iç yüzeyi ve şık dış tasarımı ile mutfağa modern bir hava katıyor.", "Kapı kolu veya düğmelerde zamanla aşınma ve arıza sorunları yaşanabiliyor.", "Isı dağılımı konusunda bazı kullanıcılar arasında şikayetler var, homojen pişirme sağlamak için dikkatli olmak gerekiyor."], ["Kusursuz temizlik, enerji ve su tasarrufu ile hayatı kolaylaştıran bir ürün. Mutlaka edinilmeli!", "Farklı program seçenekleri ve sessiz çalışma özelliği ile kullanımı çok pratik.", "Bazı modellerde su damlatma problemi yaşanabiliyor, bu da mutfakta ekstra temizlik gerektirebiliyor.", "Geniş iç hacmi sayesinde büyük tabak ve tencereleri bile sorunsuz temizleyebiliyor.", "Bazı deterjanların köpürme problemi nedeniyle programı tamamlamadan durabiliyor.", "Bazı kullanıcılar arasında kurutma performansı konusunda şikayetler var, tam olarak kurutmuyor."]]

comments

model_time_mistral = []
outputs_mistral = []
raw_outputs_mistral = []
model_time_llama = []
outputs_llama = []
raw_outputs_llama = []

for i in comments:
  out_mistral = mistral.positive_negative(i)
  out_llama = llama.positive_negative(i)

  model_time_mistral.append(out_mistral['elapsed_time_model'])
  outputs_mistral.append(out_mistral['output'])
  raw_outputs_mistral.append(out_mistral['raw_out'])

  model_time_llama.append(out_llama['elapsed_time_model'])
  outputs_llama.append(out_llama['output'])
  raw_outputs_llama.append(out_llama['raw_out'])

raw_outputs_llama

raw_outputs_mistral

model_time_mistral

model_time_llama